{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is a popular similarity measure used in machine learning and information retrieval to compare the similarity between two vectors. It is particularly useful for text mining and natural language processing tasks because it can capture the semantic meaning of words and phrases.\n",
    "\n",
    "The cosine similarity between two vectors A and B is defined as the cosine of the angle between them, which is given by the dot product of the two vectors divided by the product of their magnitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(A, B) = (A . B) / (||A|| ||B||)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where A . B is the dot product of A and B, and ||A|| and ||B|| are the magnitudes of A and B, respectively.\n",
    "\n",
    "K-nearest neighbors (KNN) is a simple machine learning algorithm used for classification and regression tasks. It works by finding the K nearest neighbors of a given test point in the training set, and predicting the label or value of the test point based on the labels or values of its K nearest neighbors.\n",
    "\n",
    "KNN can be combined with cosine similarity to perform text classification or document retrieval tasks. The idea is to represent each document as a vector of word frequencies or embeddings, and compute the cosine similarity between the test document and each training document. Then, we can find the K nearest neighbors of the test document based on their cosine similarities, and predict the label or category of the test document based on the labels or categories of its K nearest neighbors.\n",
    "\n",
    "Here's an example code for implementing KNN with cosine similarity in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the training data and labels\n",
    "X_train = ...  # matrix of training document vectors\n",
    "y_train = ...  # vector of training document labels\n",
    "\n",
    "# Load the test data\n",
    "X_test = ...   # matrix of test document vectors\n",
    "\n",
    "# Compute cosine similarities between test and training data\n",
    "cos_sim = cosine_similarity(X_test, X_train)\n",
    "\n",
    "# Initialize KNN classifier with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data based on the nearest neighbors\n",
    "y_pred = knn.predict(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we first load the training data and labels, and the test data. We then compute the cosine similarities between the test and training data using the cosine_similarity function from the sklearn.metrics.pairwise module. We initialize a KNN classifier with K=5 using the KNeighborsClassifier class from the sklearn.neighbors module, and fit the KNN model to the training data using the fit method. Finally, we predict the labels of the test data based on the nearest neighbors using the predict method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run code ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import datasets,preprocessing,model_selection,metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,), (150, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x , y = datasets.load_iris(return_X_y=True)\n",
    "x_normalize = preprocessing.StandardScaler()\n",
    "x_norm = x_normalize.fit_transform(x)\n",
    "x.shape,y.shape,x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the training data and labels\n",
    "# X_train = ...  # matrix of training document vectors\n",
    "# y_train = ...  # vector of training document labels\n",
    "x_train,x_test,y_train,y_test= model_selection.train_test_split(x_norm,y,test_size=.1,random_state=42,stratify=y)\n",
    "# Load the test data\n",
    "# X_test = ...   # matrix of test document vectors\n",
    "\n",
    "# Compute cosine similarities between test and training data\n",
    "cos_sim = cosine_similarity(x_test, x_train)\n",
    "\n",
    "# Initialize KNN classifier with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data based on the nearest neighbors\n",
    "# y_pred = knn.predict(cos_sim)\n",
    "y_pred = knn.predict(x_test)\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Preprocess the data\n",
    "docs = [\"This is the first document.\", \"This is the second document.\", \"This is the third document.\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cos_sim = cosine_similarity(X)\n",
    "\n",
    "# Define K for KNN\n",
    "K = 2\n",
    "\n",
    "# Fit KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=K, metric='cosine')\n",
    "knn.fit(X, [0, 1, 2]) # Assumes a 3-class problem, one for each document\n",
    "\n",
    "# Classify a new document\n",
    "new_doc = \"This is a new document.\"\n",
    "new_doc_vec = vectorizer.transform([new_doc])\n",
    "pred = knn.predict(new_doc_vec)\n",
    "\n",
    "print(\"Predicted class:\", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
